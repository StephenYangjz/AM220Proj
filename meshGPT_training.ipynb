{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Note: you may need to restart the kernel to use updated packages.\n"
               ]
            }
         ],
         "source": [
            "pip install  -q git+https://github.com/MarcusLoppe/meshgpt-pytorch.git"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/stephen/anaconda3/envs/meshgpt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                  "  from .autonotebook import tqdm as notebook_tqdm\n"
               ]
            }
         ],
         "source": [
            "import torch\n",
            "import trimesh\n",
            "import numpy as np\n",
            "import os\n",
            "import csv\n",
            "import json\n",
            "from collections import OrderedDict\n",
            "\n",
            "from meshgpt_pytorch import (\n",
            "    MeshTransformerTrainer,\n",
            "    MeshAutoencoderTrainer,\n",
            "    MeshAutoencoder,\n",
            "    MeshTransformer\n",
            ")\n",
            "from meshgpt_pytorch.data import ( \n",
            "    derive_face_edges_from_faces\n",
            ") \n",
            "\n",
            "def get_mesh(file_path): \n",
            "    mesh = trimesh.load(file_path, force='mesh')\n",
            "    vertices = mesh.vertices.tolist()\n",
            "    if \".off\" in file_path:  # ModelNet dataset\n",
            "       mesh.vertices[:, [1, 2]] = mesh.vertices[:, [2, 1]]\n",
            " \n",
            "       rotation_matrix = trimesh.transformations.rotation_matrix(np.radians(-90), [0, 1, 0])\n",
            "       mesh.apply_transform(rotation_matrix)\n",
            "\n",
            "        # Extract vertices and faces from the rotated mesh\n",
            "       vertices = mesh.vertices.tolist()\n",
            "            \n",
            "    faces = mesh.faces.tolist()\n",
            "    # Center\n",
            "    centered_vertices = vertices - np.mean(vertices, axis=0)\n",
            "    # Limit vertices to [-0.95, 0.95]\n",
            "    max_abs = np.max(np.abs(centered_vertices))\n",
            "    vertices = centered_vertices / (max_abs / 0.95)   \n",
            "     \n",
            "    # To ensure that the mesh models are on the \"ground\", I think this might help the models learn better if they always knows the ground plane\n",
            "    # If you dont do this, the models will 'hover' in the air \n",
            "    min_y = np.min(vertices[:, 1]) \n",
            "    difference = -0.95 - min_y \n",
            "    vertices[:, 1] += difference\n",
            "    \n",
            "    def sort_vertices(vertex):\n",
            "        return vertex[1], vertex[2], vertex[0]   \n",
            " \n",
            "    seen = OrderedDict()\n",
            "    for point in vertices: \n",
            "      key = tuple(point)\n",
            "      if key not in seen:\n",
            "        seen[key] = point\n",
            "        \n",
            "    unique_vertices =  list(seen.values()) \n",
            "    sorted_vertices = sorted(unique_vertices, key=sort_vertices)\n",
            "      \n",
            "    vertices_as_tuples = [tuple(v) for v in vertices]\n",
            "    sorted_vertices_as_tuples = [tuple(v) for v in sorted_vertices]\n",
            "\n",
            "    vertex_map = {old_index: new_index for old_index, vertex_tuple in enumerate(vertices_as_tuples) for new_index, sorted_vertex_tuple in enumerate(sorted_vertices_as_tuples) if vertex_tuple == sorted_vertex_tuple} \n",
            "    reindexed_faces = [[vertex_map[face[0]], vertex_map[face[1]], vertex_map[face[2]]] for face in faces]\n",
            "    # Code for cyclically permuted faces, used in paper (not recommended if you are using datasets from many sources)    \n",
            "    #sorted_faces = [sub_arr[sub_arr.index(min(sub_arr)):] + sub_arr[:sub_arr.index(min(sub_arr))] for sub_arr in reindexed_faces]\n",
            "    sorted_faces = [sorted(sub_arr) for sub_arr in reindexed_faces]  \n",
            "    \n",
            "    return np.array(sorted_vertices), np.array(sorted_faces)\n",
            " \n",
            " \n",
            "\n",
            "def augment_mesh(vertices, scale_factor):     \n",
            "    jitter_factor=0.01 \n",
            "    possible_values = np.arange(-jitter_factor, jitter_factor , 0.0005) \n",
            "    offsets = np.random.choice(possible_values, size=vertices.shape) \n",
            "    vertices = vertices + offsets   \n",
            "    \n",
            "    vertices = vertices * scale_factor\n",
            "    \n",
            "    # To ensure that the mesh models are on the \"ground\", I think this might help the models learn better if they always knows the ground plane\n",
            "    # If you dont do this, the models will 'hover' in the air \n",
            "    min_y = np.min(vertices[:, 1])  \n",
            "    difference = -0.95 - min_y \n",
            "    vertices[:, 1] += difference\n",
            "    return vertices\n",
            "\n",
            "\n",
            "#load_shapenet(\"./shapenet\", \"./shapenet_csv_files\", 10, 10)   \n",
            "#Find the csv files with the labels in the ShapeNetCore.v1.zip, download at  https://huggingface.co/datasets/ShapeNet/ShapeNetCore-archive  \n",
            "def load_shapenet(directory, per_category, variations ):\n",
            "    obj_datas = []   \n",
            "    chosen_models_count = {}    \n",
            "    print(f\"per_category: {per_category} variations {variations}\")\n",
            "    \n",
            "    with open('shapenet_labels.json' , 'r') as f:\n",
            "        id_info = json.load(f) \n",
            "    \n",
            "    possible_values = np.arange(0.75, 1.0 , 0.005) \n",
            "    scale_factors = np.random.choice(possible_values, size=variations) \n",
            "    \n",
            "    for category in os.listdir(directory): \n",
            "        category_path = os.path.join(directory, category)   \n",
            "        if os.path.isdir(category_path) == False:\n",
            "            continue \n",
            "        \n",
            "        num_files_in_category = len(os.listdir(category_path))\n",
            "        print(f\"{category_path} got {num_files_in_category} files\") \n",
            "        chosen_models_count[category] = 0  \n",
            "        \n",
            "        for filename in os.listdir(category_path):\n",
            "            if filename.endswith((\".obj\", \".glb\", \".off\")):\n",
            "                file_path = os.path.join(category_path, filename)\n",
            "                \n",
            "                if chosen_models_count[category] >= per_category:\n",
            "                    break\n",
            "                \n",
            "                if os.path.getsize(file_path) >  20 * 1024: # 20 kb limit = less then 400-600 faces\n",
            "                    continue\n",
            "                    \n",
            "                if filename[:-4] not in id_info:\n",
            "                    print(\"Unable to find id info for \", filename)\n",
            "                    continue \n",
            "                vertices, faces = get_mesh(file_path) \n",
            "                if len(faces) > 800: \n",
            "                    continue\n",
            "                \n",
            "                chosen_models_count[category] += 1  \n",
            "                textName = id_info[filename[:-4]]  \n",
            "                \n",
            "                \n",
            "                face_edges =  derive_face_edges_from_faces(faces)  \n",
            "                for scale_factor in scale_factors: \n",
            "                    aug_vertices = augment_mesh(vertices.copy(), scale_factor)   \n",
            "                    obj_data = {\"vertices\": torch.tensor(aug_vertices.tolist(), dtype=torch.float).to(\"cuda\"), \"faces\":  torch.tensor(faces.tolist(), dtype=torch.long).to(\"cuda\"), \"face_edges\" : face_edges, \"texts\": textName }  \n",
            "                    obj_datas.append(obj_data)\n",
            "                    \n",
            "    print(\"=\"*25)\n",
            "    print(\"Chosen models count for each category:\")\n",
            "    for category, count in chosen_models_count.items():\n",
            "        print(f\"{category}: {count}\")\n",
            "    \n",
            "    total_chosen_models = sum(chosen_models_count.values())\n",
            "    print(f\"Total number of chosen models: {total_chosen_models}\")\n",
            "    return obj_datas\n",
            "\n",
            "  \n",
            "   \n",
            "def load_filename(directory, variations):\n",
            "    obj_datas = []    \n",
            "    possible_values = np.arange(0.75, 1.0 , 0.005) \n",
            "    scale_factors = np.random.choice(possible_values, size=variations) \n",
            "    \n",
            "    for filename in os.listdir(directory):\n",
            "        if filename.endswith((\".obj\", \".glb\", \".off\")): \n",
            "            file_path = os.path.join(directory, filename) \n",
            "            vertices, faces = get_mesh(file_path)  \n",
            "            \n",
            "            faces = torch.tensor(faces.tolist(), dtype=torch.long).to(\"cuda\")\n",
            "            face_edges =  derive_face_edges_from_faces(faces)  \n",
            "            texts, ext = os.path.splitext(filename)     \n",
            "            \n",
            "            for scale_factor in scale_factors: \n",
            "                aug_vertices = augment_mesh(vertices.copy(), scale_factor)  \n",
            "                obj_data = {\"vertices\": torch.tensor(aug_vertices.tolist(), dtype=torch.float).to(\"cuda\"), \"faces\":  faces, \"face_edges\" : face_edges, \"texts\": texts } \n",
            "                obj_datas.append(obj_data)\n",
            "                     \n",
            "    print(f\"[create_mesh_dataset] Returning {len(obj_data)} meshes\")\n",
            "    return obj_datas"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "import gzip,json\n",
            "from tqdm import tqdm\n",
            "\n",
            "def load_objverse(directory, variations ):\n",
            "    obj_datas = []     \n",
            "    id_info = {}   \n",
            "    with open('./objaverse/metadata.json' , 'r') as f:\n",
            "        id_info = json.load(f) \n",
            "        \n",
            "    possible_values = np.arange(0.75, 1.0) \n",
            "    scale_factors = np.random.choice(possible_values, size=variations) \n",
            "    \n",
            "    for folder in os.listdir(directory):  \n",
            "        full_folder_path = os.path.join(directory, folder)   \n",
            "        if os.path.isdir(full_folder_path) == False:\n",
            "            continue    \n",
            "         \n",
            "        for filename in tqdm(os.listdir(full_folder_path)):  \n",
            "            if filename.endswith((\".obj\", \".glb\", \".off\")):\n",
            "                file_path = os.path.join(full_folder_path, filename)\n",
            "                kb = os.path.getsize(file_path)  / 1024 \n",
            "                if kb < 1 or kb > 30:\n",
            "                    continue\n",
            "                  \n",
            "                if filename[:-4] not in id_info: \n",
            "                    continue   \n",
            "                textName =  id_info[filename[:-4]]['name']\n",
            "                try:    \n",
            "                    vertices, faces = get_mesh(file_path)   \n",
            "                except Exception as e:\n",
            "                    continue\n",
            "                \n",
            "                if len(faces) > 250 or len(faces) < 50: \n",
            "                    continue\n",
            "                \n",
            "                faces = torch.tensor(faces.tolist(), dtype=torch.long).to(\"cuda\")\n",
            "                face_edges = derive_face_edges_from_faces(faces)   \n",
            "                for scale_factor in scale_factors: \n",
            "                    aug_vertices = augment_mesh(vertices.copy(), scale_factor)   \n",
            "                    obj_data = {\"filename\": filename, \"vertices\": torch.tensor(aug_vertices.tolist(), dtype=torch.float).to(\"cuda\"), \"faces\":  faces, \"face_edges\" : face_edges, \"texts\": textName }   \n",
            "                    obj_datas.append(obj_data)  \n",
            "    return obj_datas"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[MeshDataset] Loaded 450 entrys\n",
                  "[MeshDataset] Created from 450 entrys\n",
                  "dict_keys(['vertices', 'faces', 'face_edges', 'texts'])\n"
               ]
            }
         ],
         "source": [
            "from pathlib import Path \n",
            "import gc     \n",
            "import os\n",
            "from meshgpt_pytorch import MeshDataset \n",
            " \n",
            "project_name = \"demo_mesh\" \n",
            "\n",
            "working_dir = f'.\\{project_name}'\n",
            "\n",
            "working_dir = Path(working_dir)\n",
            "working_dir.mkdir(exist_ok = True, parents = True)\n",
            "dataset_path = working_dir / (project_name + \".npz\")\n",
            "\n",
            "\n",
            "if not os.path.isfile(dataset_path):\n",
            "    data = load_filename(\"./demo_mesh\",50)  \n",
            "    dataset = MeshDataset(data) \n",
            "    dataset.generate_face_edges() \n",
            "    print(set(item[\"texts\"] for item in dataset.data)  ) \n",
            "    dataset.save(dataset_path)\n",
            " \n",
            "dataset = MeshDataset.load(dataset_path) \n",
            "print(dataset.data[0].keys())\n",
            " "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Objaverse, instructions to download meshes: https://github.com/MarcusLoppe/Objaverse-downloader/tree/main"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# from pathlib import Path \n",
            "# import gc    \n",
            "# import torch\n",
            "# import os\n",
            "# from meshgpt_pytorch import MeshDataset \n",
            "\n",
            "# project_name = \"objaverse_dataset\"  \n",
            "\n",
            "# working_dir = f'./datasets/{project_name}' \n",
            "# working_dir = Path(working_dir)\n",
            "# working_dir.mkdir(exist_ok = True, parents = True)\n",
            "# dataset_path = working_dir / (project_name + \".npz\")\n",
            "\n",
            "\n",
            "# if not os.path.isfile(dataset_path):\n",
            "#     data = load_objverse(\"./objaverse\",10)  \n",
            "#     objverse_dataset = MeshDataset(data) \n",
            "#     objverse_dataset.generate_face_edges() \n",
            "#     print(set(item[\"texts\"] for item in objverse_dataset.data)  ) \n",
            "#     objverse_dataset.save(dataset_path)\n",
            " \n",
            "# objverse_dataset = MeshDataset.load(dataset_path) \n",
            "# print(objverse_dataset.data[0].keys()) "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Combind datasets"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "# from pathlib import Path \n",
            "# import gc    \n",
            "# import torch \n",
            "# from meshgpt_pytorch import MeshDataset\n",
            "# torch.cuda.empty_cache()\n",
            "# gc.collect()  \n",
            " \n",
            "# project_name = \"objverse_shapenet_combined\" \n",
            "\n",
            "# working_dir = f'./datasets/{project_name}' \n",
            "# working_dir = Path(working_dir)\n",
            "# working_dir.mkdir(exist_ok = True, parents = True)\n",
            "# dataset_path = working_dir / (project_name + \".npz\")\n",
            " \n",
            "# objverse_dataset.data.extend(dataset.data) \n",
            "# objverse_dataset.save(dataset_path)    "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Inspect"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "from pathlib import Path\n",
            " \n",
            "folder = working_dir / f'renders' \n",
            "obj_file_path = Path(folder)\n",
            "obj_file_path.mkdir(exist_ok = True, parents = True)\n",
            "   \n",
            "all_vertices = []\n",
            "all_faces = []\n",
            "vertex_offset = 0\n",
            "translation_distance = 0.5  \n",
            "\n",
            "for r, item in enumerate(dataset): \n",
            "    vertices_copy =  np.copy(item['vertices'].cpu())\n",
            "    vertices_copy += translation_distance * (r / 0.2 - 1) \n",
            "    \n",
            "    for vertex in vertices_copy:\n",
            "        all_vertices.append(f\"v {float(vertex[0])}  {float(vertex[1])}  {float(vertex[2])}\\n\") \n",
            "    for face in item['faces']:\n",
            "        all_faces.append(f\"f {face[0]+1+ vertex_offset} {face[1]+ 1+vertex_offset} {face[2]+ 1+vertex_offset}\\n\")  \n",
            "    vertex_offset = len(all_vertices)\n",
            " \n",
            "obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n",
            " \n",
            "obj_file_path = f'{folder}/3d_models_inspect.obj'\n",
            "\n",
            "with open(obj_file_path, \"w\") as file:\n",
            "    file.write(obj_file_content)    \n",
            "    "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Train!"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "decoder Total parameters: 19.4M\n",
                  "encoders Total parameters: 0.7M\n",
                  "Total parameters: 50.7M\n"
               ]
            }
         ],
         "source": [
            "num_layers = 23 \n",
            "autoencoder = MeshAutoencoder(     \n",
            "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
            "        dim_codebook = 192,  \n",
            "        dim_area_embed = 16,\n",
            "        dim_coor_embed = 16, \n",
            "        dim_normal_embed = 16,\n",
            "        dim_angle_embed = 8,\n",
            "    \n",
            "    attn_decoder_depth  = 4,\n",
            "    attn_encoder_depth = 2\n",
            ").to(\"cuda\")    \n",
            "\n",
            "total_params = sum(p.numel() for p in autoencoder.decoders.parameters()) \n",
            "total_params = f\"{total_params / 1000000:.1f}M\"\n",
            "print(f\"decoder Total parameters: {total_params}\") \n",
            "total_params = sum(p.numel() for p in autoencoder.encoders.parameters()) \n",
            "total_params = f\"{total_params / 1000000:.1f}M\"\n",
            "print(f\"encoders Total parameters: {total_params}\")   \n",
            "total_params = sum(p.numel() for p in autoencoder.parameters()) \n",
            "total_params = f\"{total_params / 1000000:.1f}M\"\n",
            "print(f\"Total parameters: {total_params}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Have at least 400-2000 items in the dataset, use this to multiply the dataset**  "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "4500\n"
               ]
            }
         ],
         "source": [
            "dataset.data = [dict(d) for d in dataset.data] * 10\n",
            "print(len(dataset.data))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Load previous saved model if you had to restart session*"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100, batch_size=8,  grad_accum_every=1, learning_rate = 1e-4) \n",
            "autoencoder_trainer.load('mesh-encoder_16k_2_4_0.339.pt')   \n",
            "autencoder = autoencoder_trainer.model\n",
            "for param in autoencoder.parameters():\n",
            "    param.requires_grad = True"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Train to about 0.3 loss if you are using a small dataset**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "# autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n",
            "#                                              batch_size=8,\n",
            "#                                              grad_accum_every=2,\n",
            "#                                              learning_rate = 4e-3) \n",
            "# loss = autoencoder_trainer.train(280,stop_at_loss = 0.28, diplay_graph= True)     "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "# autoencoder_trainer.save(f'{working_dir}\\mesh-encoder_{project_name}.pt')   "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Highest face count: 272\n",
                  "Max token sequence: 1632\n",
                  "Decoder total parameters: 321.3M\n",
                  "Total parameters: 440.6M\n"
               ]
            }
         ],
         "source": [
            "import gc  \n",
            "torch.cuda.empty_cache()\n",
            "gc.collect()  \n",
            "\n",
            "max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d) \n",
            "max_seq = max_length * 6  \n",
            "print(\"Highest face count:\" , max_length)\n",
            "print(\"Max token sequence:\" , max_seq) \n",
            "\n",
            "transformer = MeshTransformer(\n",
            "    autoencoder,\n",
            "    dim =768,\n",
            "    coarse_pre_gateloop_depth = 6,  \n",
            "    fine_pre_gateloop_depth= 4, \n",
            "    attn_depth = 24,  \n",
            "    attn_heads = 16,\n",
            "    dropout  = 0.0,\n",
            "    max_seq_len = 1500,\n",
            "    condition_on_text = True, \n",
            "    gateloop_use_heinsen = False,\n",
            "    text_condition_model_types = \"bge\", \n",
            "    text_condition_cond_drop_prob = 0.0, \n",
            ") \n",
            "\n",
            "total_params = sum(p.numel() for p in transformer.decoder.parameters())\n",
            "total_params = f\"{total_params / 1000000:.1f}M\"\n",
            "print(f\"Decoder total parameters: {total_params}\") \n",
            "total_params = sum(p.numel() for p in transformer.parameters())\n",
            "total_params = f\"{total_params / 1000000:.1f}M\"\n",
            "print(f\"Total parameters: {total_params}\") "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## **Required!**, embed the text and run generate_codes to save 4-96 GB VRAM (dependant on dataset) ##\n",
            "\n",
            "**If you don't;** <br>\n",
            "During each during each training step the autoencoder will generate the codes and the text encoder will embed the text.\n",
            "<br>\n",
            "After these fields are generate: **they will be deleted and next time it generates the code again:**<br>\n",
            "\n",
            "This is due to the dataloaders nature, it writes this information to a temporary COPY of the dataset\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'circle chair', 'bar chair', 'designer chair', 'designer sloped chair', 'corner table', 'high chair', 'glass table', 'office table', 'tv table'}\n",
                  "[MeshDataset] Generated 9 text_embeddings\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 90/90 [00:03<00:00, 23.08it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[MeshDataset] Generated codes for 4500 entrys\n",
                  "dict_keys(['vertices', 'faces', 'face_edges', 'text_embeds', 'codes'])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "labels = set(item[\"texts\"] for item in dataset.data)\n",
            "print(labels)\n",
            "dataset.embed_texts(transformer, batch_size = 25)\n",
            "dataset.generate_codes(autoencoder, batch_size = 50) # Higher batch size = faster but might leave some uncollected garbage in the VRAM\n",
            "print(dataset.data[0].keys())"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Load previous saved model if you had to restart session*"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [],
         "source": [
            "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100, dataset = dataset, learning_rate = 1e-1, batch_size=2)\n",
            "trainer.load('mesh-transformer_16k_768_24_16_loss_2.147.pt')  \n",
            "transformer = trainer.model"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Train to about 0.0001 loss (or less) if you are using a small dataset**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "# trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=4,num_train_steps=100, dataset = dataset,\n",
            "#                                  learning_rate = 1e-3, batch_size=8)  \n",
            "# loss = trainer.train(100, stop_at_loss = 0.009) \n",
            "\n",
            "# trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=4,num_train_steps=100, dataset = dataset,\n",
            "#                                  learning_rate = 5e-4, batch_size=8)\n",
            "# loss = trainer.train(200, stop_at_loss = 0.00001)  "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            " \n",
            "# trainer.save(f'{working_dir}\\mesh-transformer_{project_name}.pt')   "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Generate and view mesh"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "def combind_mesh(path, mesh):\n",
            "    all_vertices = []\n",
            "    all_faces = []\n",
            "    vertex_offset = 0\n",
            "    translation_distance = 0.5  \n",
            "\n",
            "    for r, faces_coordinates in enumerate(mesh): \n",
            "        numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)   \n",
            "    \n",
            "        for vertex in numpy_data:\n",
            "            all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
            "    \n",
            "        for i in range(1, len(numpy_data), 3):\n",
            "            all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n",
            "    \n",
            "        vertex_offset += len(numpy_data)\n",
            "    \n",
            "    obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n",
            "     \n",
            "    with open(path , \"w\") as file:\n",
            "        file.write(obj_file_content)   \n",
            " \n",
            "def combind_mesh_with_rows(path, meshes):\n",
            "    all_vertices = []\n",
            "    all_faces = []\n",
            "    vertex_offset = 0\n",
            "    translation_distance = 0.5  \n",
            "    \n",
            "    for row, mesh in enumerate(meshes): \n",
            "        for r, faces_coordinates in enumerate(mesh): \n",
            "            numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)  \n",
            "            numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)  \n",
            "            numpy_data[:, 2] += translation_distance * (row / 0.2 - 1)  \n",
            "        \n",
            "            for vertex in numpy_data:\n",
            "                all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
            "        \n",
            "            for i in range(1, len(numpy_data), 3):\n",
            "                all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n",
            "        \n",
            "            vertex_offset += len(numpy_data)\n",
            "        \n",
            "        obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n",
            "     \n",
            "    with open(path , \"w\") as file:\n",
            "        file.write(obj_file_content)   \n",
            "        \n",
            "        \n",
            "def write_mesh_output(path, coords):\n",
            "    numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)  \n",
            "    obj_file_content = \"\"\n",
            "    \n",
            "    for vertex in numpy_data:\n",
            "        obj_file_content += f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\"\n",
            "\n",
            "    for i in range(1, len(numpy_data), 3):\n",
            "        obj_file_content += f\"f {i} {i + 1} {i + 2}\\n\"\n",
            " \n",
            "    with open(path, \"w\") as file:\n",
            "        file.write(obj_file_content) \n",
            "         "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Using only text**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating circle chair\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 146.06it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating bar chair\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 44%|████▍     | 660/1500 [00:04<00:05, 148.79it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating designer chair\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 144.39it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating designer sloped chair\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 147.59it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating corner table\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 147.57it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating high chair\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:06, 139.43it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating glass table\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:06, 139.29it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating office table\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:06, 138.96it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating tv table\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:06, 139.67it/s]\n"
               ]
            }
         ],
         "source": [
            " \n",
            "from pathlib import Path\n",
            " \n",
            "folder = working_dir / 'renders'\n",
            "obj_file_path = Path(folder)\n",
            "obj_file_path.mkdir(exist_ok = True, parents = True)  \n",
            " \n",
            "text_coords = [] \n",
            "for text in labels:\n",
            "    print(f\"Generating {text}\")\n",
            "    faces_coordinates = transformer.generate(texts = [text],  temperature = 0.0) \n",
            "    text_coords.append(faces_coordinates)\n",
            "    \n",
            "    write_mesh_output(f'{folder}/3d_output_{text}.obj', faces_coordinates)  \n",
            "     \n",
            " \n",
            "combind_mesh(f'{folder}/3d_models_all.obj', text_coords)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1488/1500 [00:10<00:00, 135.94it/s]\n"
               ]
            }
         ],
         "source": [
            "faces_coordinates = transformer.generate(texts = [\"table\"],  temperature = 0.5) "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [],
         "source": [
            "write_mesh_output('test.obj', faces_coordinates)  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Text + prompt of tokens**"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Grab fresh copy of dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[MeshDataset] Loaded 450 entrys\n",
                  "[MeshDataset] Created from 450 entrys\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 0/18 [00:00<?, ?it/s]"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 18/18 [00:00<00:00, 20.74it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[MeshDataset] Generated codes for 450 entrys\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "\n"
               ]
            }
         ],
         "source": [
            "dataset = MeshDataset.load(dataset_path)\n",
            "dataset.generate_codes(autoencoder)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Prompt with 10% of codes/tokens**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating circle chair with 67 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  1%|          | 12/1433 [00:00<00:12, 115.28it/s]"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  5%|▌         | 77/1433 [00:00<00:09, 140.95it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/circle chair_67_tokens.obj\n",
                  "Generating bar chair with 67 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 45%|████▌     | 647/1433 [00:04<00:05, 147.11it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/bar chair_67_tokens.obj\n",
                  "Generating designer chair with 76 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 88%|████████▊ | 1256/1424 [00:08<00:01, 141.50it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/designer chair_76_tokens.obj\n",
                  "Generating designer sloped chair with 81 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 10%|▉         | 135/1419 [00:01<00:09, 133.56it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/designer sloped chair_81_tokens.obj\n",
                  "Generating corner table with 64 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1436/1436 [00:09<00:00, 147.74it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/corner table_64_tokens.obj\n",
                  "Generating high chair with 67 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1421/1433 [00:09<00:00, 149.18it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/high chair_67_tokens.obj\n",
                  "Generating glass table with 21 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1479/1479 [00:09<00:00, 148.57it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/glass table_21_tokens.obj\n",
                  "Generating office table with 50 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1438/1450 [00:09<00:00, 145.88it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/office table_50_tokens.obj\n",
                  "Generating tv table with 74 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 20%|██        | 286/1426 [00:01<00:07, 147.01it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes/tv table_74_tokens.obj\n"
               ]
            }
         ],
         "source": [
            "from pathlib import Path\n",
            "token_length_procent = 0.10 \n",
            "codes = []\n",
            "texts = []\n",
            "for label in labels:\n",
            "    for item in dataset.data: \n",
            "        if item['texts'] == label:\n",
            "            num_tokens = int(item[\"codes\"].shape[0] * token_length_procent) \n",
            "            \n",
            "            texts.append(item['texts']) \n",
            "            codes.append(item[\"codes\"].flatten()[:num_tokens].unsqueeze(0))  \n",
            "            break\n",
            "        \n",
            "folder = working_dir / f'renders/text+codes'\n",
            "obj_file_path = Path(folder)\n",
            "obj_file_path.mkdir(exist_ok = True, parents = True)  \n",
            "\n",
            "coords = [] \n",
            "\n",
            "\n",
            "\n",
            "for text, prompt in zip(texts, codes): \n",
            "    print(f\"Generating {text} with {prompt.shape[1]} tokens\")\n",
            "    faces_coordinates = transformer.generate(texts = [text],  prompt = prompt, temperature = 0) \n",
            "    coords.append(faces_coordinates) \n",
            "    \n",
            "    obj_file_path = f'{folder}/{text}_{prompt.shape[1]}_tokens.obj'\n",
            "    write_mesh_output(obj_file_path, faces_coordinates)\n",
            "        \n",
            "    print(obj_file_path)\n",
            "     \n",
            " \n",
            "combind_mesh(f'{folder}/text+prompt_all.obj', coords)\n",
            "\n",
            "if text_coords is not None: \n",
            "    combind_mesh_with_rows(f'{folder}/both_verisons.obj', [text_coords , coords])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Prompt with 0% to 80% of tokens**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Generating circle chair with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 0/1500 [00:00<?, ?it/s]"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 149.03it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_0_tokens.obj\n",
                  "Generating bar chair with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 44%|████▍     | 660/1500 [00:04<00:05, 149.51it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_0_tokens.obj\n",
                  "Generating designer chair with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 149.48it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_0_tokens.obj\n",
                  "Generating designer sloped chair with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 147.59it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_0_tokens.obj\n",
                  "Generating corner table with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 149.36it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_0_tokens.obj\n",
                  "Generating high chair with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 148.72it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_0_tokens.obj\n",
                  "Generating glass table with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 149.21it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_0_tokens.obj\n",
                  "Generating office table with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 149.16it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_0_tokens.obj\n",
                  "Generating tv table with 0 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 43%|████▎     | 648/1500 [00:04<00:05, 148.95it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_0_tokens.obj\n",
                  "Generating circle chair with 67 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  5%|▌         | 77/1433 [00:00<00:09, 141.46it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_67_tokens.obj\n",
                  "Generating bar chair with 67 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 45%|████▌     | 647/1433 [00:04<00:05, 145.96it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_67_tokens.obj\n",
                  "Generating designer chair with 76 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 88%|████████▊ | 1256/1424 [00:08<00:01, 148.77it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_76_tokens.obj\n",
                  "Generating designer sloped chair with 81 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 10%|▉         | 135/1419 [00:00<00:09, 141.75it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_81_tokens.obj\n",
                  "Generating corner table with 64 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1436/1436 [00:09<00:00, 144.39it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_64_tokens.obj\n",
                  "Generating high chair with 67 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1421/1433 [00:10<00:00, 142.01it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_67_tokens.obj\n",
                  "Generating glass table with 21 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1479/1479 [00:09<00:00, 148.87it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_21_tokens.obj\n",
                  "Generating office table with 50 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1438/1450 [00:10<00:00, 141.75it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_50_tokens.obj\n",
                  "Generating tv table with 74 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 20%|██        | 286/1426 [00:01<00:07, 148.05it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_74_tokens.obj\n",
                  "Generating circle chair with 134 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 11%|█▏        | 154/1366 [00:01<00:08, 145.37it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_134_tokens.obj\n",
                  "Generating bar chair with 134 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1366/1366 [00:09<00:00, 150.91it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_134_tokens.obj\n",
                  "Generating designer chair with 152 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 15%|█▌        | 208/1348 [00:01<00:07, 147.76it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_152_tokens.obj\n",
                  "Generating designer sloped chair with 163 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  4%|▍         | 53/1337 [00:00<00:09, 137.74it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_163_tokens.obj\n",
                  "Generating corner table with 129 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1371/1371 [00:09<00:00, 150.33it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_129_tokens.obj\n",
                  "Generating high chair with 134 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1354/1366 [00:09<00:00, 149.91it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_134_tokens.obj\n",
                  "Generating glass table with 43 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 12%|█▏        | 173/1457 [00:01<00:08, 146.92it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_43_tokens.obj\n",
                  "Generating office table with 100 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  8%|▊         | 116/1400 [00:00<00:08, 143.16it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_100_tokens.obj\n",
                  "Generating tv table with 148 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1352/1352 [00:08<00:00, 151.84it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_148_tokens.obj\n",
                  "Generating circle chair with 201 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 12%|█▏        | 159/1299 [00:01<00:07, 145.54it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_201_tokens.obj\n",
                  "Generating bar chair with 201 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 34%|███▍      | 447/1299 [00:03<00:05, 148.98it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_201_tokens.obj\n",
                  "Generating designer chair with 228 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 10%|█         | 132/1272 [00:00<00:07, 146.16it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_228_tokens.obj\n",
                  "Generating designer sloped chair with 244 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  9%|▉         | 116/1256 [00:00<00:08, 141.60it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_244_tokens.obj\n",
                  "Generating corner table with 194 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  7%|▋         | 94/1306 [00:00<00:08, 143.10it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_194_tokens.obj\n",
                  "Generating high chair with 201 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 34%|███▍      | 447/1299 [00:02<00:05, 149.28it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_201_tokens.obj\n",
                  "Generating glass table with 64 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 56%|█████▌    | 800/1436 [00:05<00:04, 150.09it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_64_tokens.obj\n",
                  "Generating office table with 151 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 42%|████▏     | 569/1349 [00:03<00:05, 150.08it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_151_tokens.obj\n",
                  "Generating tv table with 223 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 16%|█▋        | 209/1277 [00:01<00:07, 148.01it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_223_tokens.obj\n",
                  "Generating circle chair with 268 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  7%|▋         | 92/1232 [00:00<00:08, 141.27it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_268_tokens.obj\n",
                  "Generating bar chair with 268 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1232/1232 [00:08<00:00, 150.61it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_268_tokens.obj\n",
                  "Generating designer chair with 304 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  5%|▍         | 56/1196 [00:00<00:08, 135.17it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_304_tokens.obj\n",
                  "Generating designer sloped chair with 326 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 21%|██▏       | 250/1174 [00:01<00:06, 146.21it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_326_tokens.obj\n",
                  "Generating corner table with 259 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 37%|███▋      | 461/1241 [00:03<00:05, 149.62it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_259_tokens.obj\n",
                  "Generating high chair with 268 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1220/1232 [00:08<00:00, 150.26it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_268_tokens.obj\n",
                  "Generating glass table with 86 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1402/1414 [00:09<00:00, 150.42it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_86_tokens.obj\n",
                  "Generating office table with 201 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 34%|███▍      | 447/1299 [00:02<00:05, 149.07it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_201_tokens.obj\n",
                  "Generating tv table with 297 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 11%|█         | 135/1203 [00:00<00:07, 144.71it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_297_tokens.obj\n",
                  "Generating circle chair with 336 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 27%|██▋       | 312/1164 [00:02<00:05, 149.12it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_336_tokens.obj\n",
                  "Generating bar chair with 336 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1152/1164 [00:07<00:00, 150.26it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_336_tokens.obj\n",
                  "Generating designer chair with 381 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 30%|███       | 339/1119 [00:02<00:05, 148.04it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_381_tokens.obj\n",
                  "Generating designer sloped chair with 408 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 75%|███████▍  | 816/1092 [00:05<00:01, 148.47it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_408_tokens.obj\n",
                  "Generating corner table with 324 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 34%|███▎      | 396/1176 [00:02<00:05, 149.06it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_324_tokens.obj\n",
                  "Generating high chair with 336 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 37%|███▋      | 432/1164 [00:02<00:04, 149.64it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_336_tokens.obj\n",
                  "Generating glass table with 108 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 13%|█▎        | 180/1392 [00:01<00:08, 147.59it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_108_tokens.obj\n",
                  "Generating office table with 252 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 20%|██        | 252/1248 [00:01<00:06, 148.46it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_252_tokens.obj\n",
                  "Generating tv table with 372 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 24%|██▍       | 276/1128 [00:01<00:05, 148.73it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_372_tokens.obj\n",
                  "Generating circle chair with 403 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 97%|█████████▋| 1061/1097 [00:07<00:00, 150.17it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_403_tokens.obj\n",
                  "Generating bar chair with 403 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1085/1097 [00:07<00:00, 150.12it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_403_tokens.obj\n",
                  "Generating designer chair with 457 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 11%|█▏        | 119/1043 [00:00<00:06, 144.38it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_457_tokens.obj\n",
                  "Generating designer sloped chair with 489 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 23%|██▎       | 231/1011 [00:01<00:05, 145.26it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_489_tokens.obj\n",
                  "Generating corner table with 388 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 10%|█         | 116/1112 [00:00<00:06, 142.32it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_388_tokens.obj\n",
                  "Generating high chair with 403 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 73%|███████▎  | 797/1097 [00:05<00:02, 149.81it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_403_tokens.obj\n",
                  "Generating glass table with 129 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1371/1371 [00:09<00:00, 150.53it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_129_tokens.obj\n",
                  "Generating office table with 302 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 99%|█████████▉| 1186/1198 [00:08<00:00, 146.93it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_302_tokens.obj\n",
                  "Generating tv table with 446 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 1054/1054 [00:07<00:00, 150.10it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_446_tokens.obj\n",
                  "Generating circle chair with 470 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  3%|▎         | 34/1030 [00:00<00:07, 127.95it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/circle chair_470_tokens.obj\n",
                  "Generating bar chair with 470 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 94%|█████████▍| 970/1030 [00:06<00:00, 149.55it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/bar chair_470_tokens.obj\n",
                  "Generating designer chair with 533 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 12%|█▏        | 115/967 [00:00<00:06, 141.33it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer chair_533_tokens.obj\n",
                  "Generating designer sloped chair with 571 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  1%|          | 5/929 [00:00<00:13, 70.67it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/designer sloped chair_571_tokens.obj\n",
                  "Generating corner table with 453 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  3%|▎         | 27/1047 [00:00<00:08, 121.66it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/corner table_453_tokens.obj\n",
                  "Generating high chair with 470 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 17%|█▋        | 178/1030 [00:01<00:05, 146.36it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/high chair_470_tokens.obj\n",
                  "Generating glass table with 151 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 10%|█         | 137/1349 [00:00<00:08, 145.83it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/glass table_151_tokens.obj\n",
                  "Generating office table with 352 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 26%|██▌       | 296/1148 [00:02<00:05, 147.64it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/office table_352_tokens.obj\n",
                  "Generating tv table with 520 tokens\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  " 13%|█▎        | 128/980 [00:00<00:05, 143.03it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  ".\\demo_mesh/renders/text+codes_rows/tv table_520_tokens.obj\n"
               ]
            }
         ],
         "source": [
            "from pathlib import Path\n",
            " \n",
            "folder = working_dir / f'renders/text+codes_rows'\n",
            "obj_file_path = Path(folder)\n",
            "obj_file_path.mkdir(exist_ok = True, parents = True)   \n",
            "\n",
            "mesh_rows = []\n",
            "for token_length_procent in np.arange(0, 0.8, 0.1):\n",
            "    codes = []\n",
            "    texts = []\n",
            "    for label in labels:\n",
            "        for item in dataset.data: \n",
            "            if item['texts'] == label:\n",
            "                num_tokens = int(item[\"codes\"].shape[0] * token_length_procent) \n",
            "                \n",
            "                texts.append(item['texts']) \n",
            "                codes.append(item[\"codes\"].flatten()[:num_tokens].unsqueeze(0))  \n",
            "                break\n",
            "            \n",
            "    coords = []   \n",
            "    for text, prompt in zip(texts, codes): \n",
            "        \n",
            "        print(f\"Generating {text} with {prompt.shape[1]} tokens\")\n",
            "        faces_coordinates = transformer.generate(texts = [text],  prompt = prompt, temperature = 0) \n",
            "        coords.append(faces_coordinates)\n",
            "        \n",
            "        obj_file_path = f'{folder}/{text}_{prompt.shape[1]}_tokens.obj'\n",
            "        write_mesh_output(obj_file_path, coords)  \n",
            "        print(obj_file_path)\n",
            "        \n",
            "        \n",
            "    mesh_rows.append(coords) \n",
            "    combind_mesh(f'{folder}/text+prompt_all_{token_length_procent}.obj', coords)\n",
            "    \n",
            "combind_mesh_with_rows(f'{folder}/all.obj', mesh_rows)\n",
            " "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Just some testing for text embedding similarity**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Text                  | circle chair          | bar chair             | designer chair        | designer sloped chair | corner table          | high chair            | glass table           | office table          | tv table              | \n",
                  "circle chair          | 1.0000                | 0.7620                | 0.7766                | 0.7495                | 0.6723                | 0.7662                | 0.6020                | 0.6544                | 0.5917                | \n",
                  "bar chair             | 0.7620                | 1.0000                | 0.7795                | 0.7328                | 0.6554                | 0.7457                | 0.6507                | 0.6875                | 0.6570                | \n",
                  "designer chair        | 0.7766                | 0.7795                | 1.0000                | 0.8752                | 0.6370                | 0.7758                | 0.6006                | 0.6750                | 0.5985                | \n",
                  "designer sloped chair | 0.7495                | 0.7328                | 0.8752                | 1.0000                | 0.6411                | 0.7516                | 0.5903                | 0.6539                | 0.5940                | \n",
                  "corner table          | 0.6723                | 0.6554                | 0.6370                | 0.6411                | 1.0000                | 0.6124                | 0.8030                | 0.8024                | 0.7483                | \n",
                  "high chair            | 0.7662                | 0.7457                | 0.7758                | 0.7516                | 0.6124                | 1.0000                | 0.5766                | 0.6416                | 0.5807                | \n",
                  "glass table           | 0.6020                | 0.6507                | 0.6006                | 0.5903                | 0.8030                | 0.5766                | 1.0000                | 0.7774                | 0.7481                | \n",
                  "office table          | 0.6544                | 0.6875                | 0.6750                | 0.6539                | 0.8024                | 0.6416                | 0.7774                | 1.0000                | 0.7690                | \n",
                  "tv table              | 0.5917                | 0.6570                | 0.5985                | 0.5940                | 0.7483                | 0.5807                | 0.7481                | 0.7690                | 1.0000                | \n"
               ]
            }
         ],
         "source": [
            "import numpy as np \n",
            "texts = list(labels)\n",
            "vectors = [transformer.conditioner.text_models[0].embed_text([text], return_text_encodings = False).cpu().flatten() for text in texts]\n",
            " \n",
            "max_label_length = max(len(text) for text in texts)\n",
            " \n",
            "# Print the table header\n",
            "print(f\"{'Text':<{max_label_length}} |\", end=\" \")\n",
            "for text in texts:\n",
            "    print(f\"{text:<{max_label_length}} |\", end=\" \")\n",
            "print()\n",
            "\n",
            "# Print the similarity matrix as a table with fixed-length columns\n",
            "for i in range(len(texts)):\n",
            "    print(f\"{texts[i]:<{max_label_length}} |\", end=\" \")\n",
            "    for j in range(len(texts)):\n",
            "        # Encode the texts and calculate cosine similarity manually\n",
            "        vector_i = vectors[i]\n",
            "        vector_j = vectors[j]\n",
            "        \n",
            "        dot_product = torch.sum(vector_i * vector_j)\n",
            "        norm_vector1 = torch.norm(vector_i)\n",
            "        norm_vector2 = torch.norm(vector_j)\n",
            "        similarity_score = dot_product / (norm_vector1 * norm_vector2)\n",
            "        \n",
            "        # Print with fixed-length columns\n",
            "        print(f\"{similarity_score.item():<{max_label_length}.4f} |\", end=\" \")\n",
            "    print()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kaggle": {
         "accelerator": "gpu",
         "dataSources": [],
         "dockerImageVersionId": 30627,
         "isGpuEnabled": true,
         "isInternetEnabled": true,
         "language": "python",
         "sourceType": "notebook"
      },
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.18"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
